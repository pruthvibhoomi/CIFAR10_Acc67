{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /opt/conda/envs/pytorch/lib/python3.11/site-packages (1.5.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: albumentations in /opt/conda/envs/pytorch/lib/python3.11/site-packages (1.4.24)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from albumentations) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from albumentations) (1.14.1)\n",
            "Requirement already satisfied: PyYAML in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from albumentations) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from albumentations) (2.10.3)\n",
            "Requirement already satisfied: albucore==0.0.23 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from albumentations) (0.0.23)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from albumentations) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from albucore==0.0.23->albumentations) (3.11.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from albucore==0.0.23->albumentations) (6.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/envs/pytorch/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install torchsummary\n",
        "%pip install albumentations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xhjf7fDJMGrs"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZVyqmVzdNUw7"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3, padding=1,stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(0.25)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3, padding=1,stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(0.25)\n",
        "\n",
        "         )\n",
        "\n",
        "        self.conv4_depthwise = nn.Sequential(\n",
        "            nn.Conv2d(128, 128, 3, padding=1, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(0.1)\n",
        "         )\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc1 = nn.Linear(128  , 10)\n",
        "       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4_depthwise(x)\n",
        "        x = self.gap(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x,dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gwl9Yi9NohB",
        "outputId": "644c8e5b-48c4-4d6d-f6bd-4cccc5a90175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available? True\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 16, 16]             896\n",
            "              ReLU-2           [-1, 32, 16, 16]               0\n",
            "       BatchNorm2d-3           [-1, 32, 16, 16]              64\n",
            "           Dropout-4           [-1, 32, 16, 16]               0\n",
            "            Conv2d-5             [-1, 64, 8, 8]          18,496\n",
            "              ReLU-6             [-1, 64, 8, 8]               0\n",
            "       BatchNorm2d-7             [-1, 64, 8, 8]             128\n",
            "           Dropout-8             [-1, 64, 8, 8]               0\n",
            "            Conv2d-9            [-1, 128, 4, 4]          73,856\n",
            "             ReLU-10            [-1, 128, 4, 4]               0\n",
            "      BatchNorm2d-11            [-1, 128, 4, 4]             256\n",
            "          Dropout-12            [-1, 128, 4, 4]               0\n",
            "           Conv2d-13            [-1, 128, 4, 4]         147,584\n",
            "             ReLU-14            [-1, 128, 4, 4]               0\n",
            "      BatchNorm2d-15            [-1, 128, 4, 4]             256\n",
            "          Dropout-16            [-1, 128, 4, 4]               0\n",
            "AdaptiveAvgPool2d-17            [-1, 128, 1, 1]               0\n",
            "           Linear-18                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 242,826\n",
            "Trainable params: 242,826\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.50\n",
            "Params size (MB): 0.93\n",
            "Estimated Total Size (MB): 1.44\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from torchsummary import summary\n",
        "use_cuda =  torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", use_cuda)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.25, inplace=False)\n",
              "  )\n",
              "  (conv4_depthwise): Sequential(\n",
              "    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (gap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc1): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gHEQGlvjRne4"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def coarse_dropout(image, min_holes=1, max_holes=1, max_height=16, max_width=16, min_height=16, min_width=16, fill_value=0):\n",
        "  \"\"\"\n",
        "  Applies CoarseDropout to an image.\n",
        "\n",
        "  Args:\n",
        "    image: PIL Image to apply the dropout to.\n",
        "    min_holes: Minimum number of holes to apply.\n",
        "    max_holes: Maximum number of holes to apply.\n",
        "    max_height: Maximum height of the holes.\n",
        "    max_width: Maximum width of the holes.\n",
        "    fill_value: Value to fill the holes with.\n",
        "\n",
        "  Returns:\n",
        "    PIL Image with CoarseDropout applied.\n",
        "  \"\"\"\n",
        "  image_np = np.array(image)\n",
        "  num_holes = random.randint(min_holes, max_holes)\n",
        "\n",
        "  h, w, _ = image_np.shape  # Assuming the image is in HWC format\n",
        "\n",
        "  # Calculate the mean value of the image\n",
        "  fill_value = int(np.mean(image_np))\n",
        "\n",
        "  for _ in range(num_holes):\n",
        "    hole_h = random.randint(min_height, max_height)\n",
        "    hole_w = random.randint(min_width, max_width)\n",
        "    y = random.randint(0, h - hole_h)\n",
        "    x = random.randint(0, w - hole_w)\n",
        "\n",
        "    image_np[y:y + hole_h, x:x + hole_w, :] = fill_value\n",
        "\n",
        "  return image #return as PIL image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ruPjX7cNqIc",
        "outputId": "4ed5191d-745b-4a20-b7eb-2e3eb8e85533"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "kwargs = {'num_workers': 0, 'pin_memory': True} if use_cuda else {}\n",
        "torch.manual_seed(1)\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                    transforms.Lambda(lambda x: coarse_dropout(x)),  # Add CoarseDropout\n",
        "                    transforms.RandomHorizontalFlip(),\n",
        "                    transforms.Lambda(lambda x: np.array(x)),\n",
        "                    transforms.Lambda(lambda x: A.Compose([ # Albumentations Compose for augmentations\n",
        "                            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=10, p=0.2),\n",
        "                            # Other Albumentations transforms if needed\n",
        "                        ])(image=x)['image']), # Convert to PyTorch Tensor\n",
        "                    transforms.Lambda(lambda x: Image.fromarray(x)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.CIFAR10('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TRLcdQ5TbuwN"
      },
      "outputs": [],
      "source": [
        "# Adding a early stopping class\n",
        "\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement.\n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3aJDOKIZbZr6"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "  train_loss_sum_epoch = processed - correct\n",
        "  return train_loss_sum_epoch\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t_cFkKubjw_",
        "outputId": "3959c5fe-ea0f-420f-de72-558b063b3d89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.9167639017105103 Batch_id=781 Accuracy=42.98: 100%|██████████| 782/782 [01:08<00:00, 11.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (inf --> 28508.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 1.3106, Accuracy: 5295/10000 (52.95%)\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.2440701723098755 Batch_id=781 Accuracy=54.11: 100%|██████████| 782/782 [01:09<00:00, 11.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (28508.000000 --> 22944.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 1.1431, Accuracy: 5931/10000 (59.31%)\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.038072109222412 Batch_id=781 Accuracy=58.87: 100%|██████████| 782/782 [01:08<00:00, 11.47it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (22944.000000 --> 20567.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 1.0421, Accuracy: 6280/10000 (62.80%)\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.8617281913757324 Batch_id=781 Accuracy=64.60: 100%|██████████| 782/782 [01:08<00:00, 11.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (20567.000000 --> 17702.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 0.8894, Accuracy: 6842/10000 (68.42%)\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.7639380097389221 Batch_id=781 Accuracy=66.24: 100%|██████████| 782/782 [01:09<00:00, 11.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (17702.000000 --> 16879.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 0.8578, Accuracy: 6974/10000 (69.74%)\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.9297522902488708 Batch_id=781 Accuracy=66.74: 100%|██████████| 782/782 [01:08<00:00, 11.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (16879.000000 --> 16630.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 0.8415, Accuracy: 7021/10000 (70.21%)\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.8880215883255005 Batch_id=781 Accuracy=67.71: 100%|██████████| 782/782 [01:09<00:00, 11.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (16630.000000 --> 16147.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 0.8425, Accuracy: 7023/10000 (70.23%)\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.9501712322235107 Batch_id=781 Accuracy=67.77: 100%|██████████| 782/782 [01:06<00:00, 11.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (16147.000000 --> 16113.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 0.8402, Accuracy: 7028/10000 (70.28%)\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.9998897910118103 Batch_id=781 Accuracy=67.95: 100%|██████████| 782/782 [01:02<00:00, 12.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (16113.000000 --> 16025.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 0.8438, Accuracy: 7017/10000 (70.17%)\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.826817274093628 Batch_id=781 Accuracy=68.06: 100%|██████████| 782/782 [01:02<00:00, 12.59it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss decreased (16025.000000 --> 15972.000000).  Saving model ...\n",
            "\n",
            "Test set: Average loss: 0.8378, Accuracy: 7051/10000 (70.51%)\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.0531303882598877 Batch_id=781 Accuracy=67.82: 100%|██████████| 782/782 [01:06<00:00, 11.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 1 out of 3\n",
            "\n",
            "Test set: Average loss: 0.8416, Accuracy: 7029/10000 (70.29%)\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=1.2466462850570679 Batch_id=781 Accuracy=68.01: 100%|██████████| 782/782 [01:09<00:00, 11.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 2 out of 3\n",
            "\n",
            "Test set: Average loss: 0.8330, Accuracy: 7053/10000 (70.53%)\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loss=0.4257303476333618 Batch_id=781 Accuracy=67.85: 100%|██████████| 782/782 [01:08<00:00, 11.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "\n",
        "model = Net().to(device)\n",
        "early_stopping = EarlyStopping(patience=3, verbose=True) # patience is number of epochs to wait for improvement\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "num_epochs = 30\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    val_loss = train(model, device, train_loader, optimizer, epoch)\n",
        "    # This is to genalize the model faster\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "    # After each trained epoch , step up\n",
        "    scheduler.step()\n",
        "    test(model, device, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
